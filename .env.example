# AI Council MCP Server - Environment Variables Example
# Copy this file to .env and fill in your API keys

# ==========================================
# AI PROVIDER CONFIGURATION
# ==========================================

# Google Gemini (Primary Provider)
# Get your key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# OpenRouter (For Claude, GPT-4, Llama, etc.)
# Get your key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# Generic OpenAI-Compatible API
GENERIC_OPENAI_KEY=
GENERIC_OPENAI_ENDPOINT=http://localhost:11434/v1/chat/completions

# LM Studio (Local Models)
LM_STUDIO_ENDPOINT=http://localhost:1234/v1/chat/completions

# Ollama (Local Models)
OLLAMA_ENDPOINT=http://localhost:11434/v1/chat/completions

# Jan AI (Local Models)
JAN_AI_ENDPOINT=http://localhost:1337/v1/chat/completions

# Z.ai
ZAI_API_KEY=
ZAI_ENDPOINT=https://api.zai.com/v1/chat/completions

# Moonshot
MOONSHOT_API_KEY=
MOONSHOT_ENDPOINT=https://api.moonshot.cn/v1/chat/completions

# Minimax
MINIMAX_API_KEY=
MINIMAX_ENDPOINT=https://api.minimax.chat/v1/text/chatcompletion_v2

# ==========================================
# SERVER CONFIGURATION
# ==========================================

# Maximum concurrent API requests (default: 2)
MAX_CONCURRENT_REQUESTS=2

# Enable economy mode to reduce API costs (default: true)
ECONOMY_MODE=true

# Enable context pruning (default: true)
CONTEXT_PRUNING=true

# Maximum context turns to keep (default: 8)
MAX_CONTEXT_TURNS=8

# ==========================================
# USAGE INSTRUCTIONS
# ==========================================

# 1. Copy this file to .env:
#    cp .env.example .env

# 2. Edit .env and add your API keys

# 3. Start the server:
#    ./start.sh          # Linux/Mac
#    start.bat           # Windows

# 4. Or run with environment variables:
#    GEMINI_API_KEY=your_key ./start.sh

# Note: Only ONE provider needs to be configured
# Recommended: Start with GEMINI_API_KEY or OPENROUTER_API_KEY
