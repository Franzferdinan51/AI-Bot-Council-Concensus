# =====================================================
# AI COUNCIL MCP SERVER - CONFIGURATION FILE
# =====================================================
# Copy this file to .env and configure your settings
# cp .env.example .env
# =====================================================

# =====================================================
# SECTION 1: AI PROVIDERS (Choose at least one)
# =====================================================

# ----------------------------------------------------
# Google Gemini (Recommended - Free tier available)
# Get your API key: https://aistudio.google.com/app/apikey
# Models: gemini-2.5-flash, gemini-1.5-pro, gemini-2.5-flash-8b
# ----------------------------------------------------
GEMINI_API_KEY=

# ----------------------------------------------------
# OpenRouter (Access to Claude, GPT-4, Llama, etc.)
# Get your API key: https://openrouter.ai/keys
# Models: anthropic/claude-3.5-sonnet, openai/gpt-4o, meta-llama/llama-3.1-70b-instruct
# ----------------------------------------------------
OPENROUTER_API_KEY=

# ----------------------------------------------------
# OpenAI (Direct OpenAI API)
# Get your API key: https://platform.openai.com/api-keys
# Models: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# ----------------------------------------------------
OPENAI_API_KEY=
OPENAI_ENDPOINT=https://api.openai.com/v1/chat/completions

# ----------------------------------------------------
# Anthropic (Direct Claude API)
# Get your API key: https://console.anthropic.com/
# Models: claude-3-5-sonnet, claude-3-opus, claude-3-haiku
# ----------------------------------------------------
ANTHROPIC_API_KEY=
ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1/messages

# ----------------------------------------------------
# LM Studio (Local models - Free)
# Download: https://lmstudio.ai
# Endpoint format: http://localhost:1234/v1/chat/completions
# ----------------------------------------------------
LM_STUDIO_ENDPOINT=
# LM_STUDIO_API_KEY=  # Usually not needed for local LM Studio

# ----------------------------------------------------
# Ollama (Local models - Free)
# Install: https://ollama.ai
# Endpoint format: http://localhost:11434/v1/chat/completions
# ----------------------------------------------------
OLLAMA_ENDPOINT=
# OLLAMA_API_KEY=  # Usually not needed for local Ollama

# ----------------------------------------------------
# Jan.ai (Local models - Free)
# Download: https://jan.ai
# Endpoint format: http://localhost:1337/v1/chat/completions
# ----------------------------------------------------
JAN_AI_ENDPOINT=http://localhost:1337/v1/chat/completions

# ----------------------------------------------------
# Generic OpenAI-Compatible API
# For any OpenAI-compatible provider
# ----------------------------------------------------
GENERIC_OPENAI_API_KEY=
GENERIC_OPENAI_ENDPOINT=

# ----------------------------------------------------
# Z.ai Provider
# ----------------------------------------------------
ZAI_API_KEY=
ZAI_ENDPOINT=https://api.zai.com/v1/chat/completions

# ----------------------------------------------------
# Moonshot AI
# ----------------------------------------------------
MOONSHOT_API_KEY=
MOONSHOT_ENDPOINT=https://api.moonshot.cn/v1/chat/completions

# ----------------------------------------------------
# Minimax AI
# ----------------------------------------------------
MINIMAX_API_KEY=
MINIMAX_ENDPOINT=https://api.minimax.chat/v1/text/chatcompletion_v2

# =====================================================
# SECTION 2: CUSTOM BOT MODEL CONFIGURATIONS
# =====================================================
# Set custom models for each bot persona
# Format: MODEL_<BOT-ID>=<model-name>
# Format: AUTHOR_TYPE_<BOT-ID>=<provider>

# ----------------------------------------------------
# Speaker (High Council) - Controls the entire session
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_SPEAKER_HIGH_COUNCIL=gemini-2.5-flash
AUTHOR_TYPE_SPEAKER_HIGH_COUNCIL=gemini

# ----------------------------------------------------
# The Facilitator (Moderator) - Keeps debate on track
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_MODERATOR_FACILITATOR=gemini-2.5-flash
AUTHOR_TYPE_MODERATOR_FACILITATOR=gemini

# ----------------------------------------------------
# The Technocrat - Focus on efficiency and data
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_TECHNOCRAT=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_TECHNOCRAT=gemini

# ----------------------------------------------------
# The Ethicist - Moral frameworks and social impact
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_ETHICIST=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_ETHICIST=gemini

# ----------------------------------------------------
# The Pragmatist - Economics and feasibility
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_PRAGMATIST=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_PRAGMATIST=gemini

# ----------------------------------------------------
# The Visionary - Long-term thinking, radical innovation
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_VISIONARY=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_VISIONARY=gemini

# ----------------------------------------------------
# The Sentinel - Security and defense specialist
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_SENTINEL=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_SENTINEL=gemini

# ----------------------------------------------------
# The Historian - Uses historical precedents
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_HISTORIAN=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_HISTORIAN=gemini

# ----------------------------------------------------
# The Diplomat - International relations
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_DIPLOMAT=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_DIPLOMAT=gemini

# ----------------------------------------------------
# The Skeptic - Devil's advocate, critical thinking
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_SKEPTIC=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_SKEPTIC=gemini

# ----------------------------------------------------
# The Conspiracist - Connects hidden patterns
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_CONSPIRACIST=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_CONSPIRACIST=gemini

# ----------------------------------------------------
# The Journalist - Public interest, transparency
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_JOURNALIST=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_JOURNALIST=gemini

# ----------------------------------------------------
# The Propagandist - Narrative and perception
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_PROPAGANDIST=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_PROPAGANDIST=gemini

# ----------------------------------------------------
# The Psychologist - Human behavior and motivations
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_PSYCHOLOGIST=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_PSYCHOLOGIST=gemini

# ----------------------------------------------------
# The Libertarian - Individual liberty, minimal state
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_LIBERTARIAN=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_LIBERTARIAN=gemini

# ----------------------------------------------------
# The Progressive - Social justice, equity
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_PROGRESSIVE=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_PROGRESSIVE=gemini

# ----------------------------------------------------
# The Conservative - Tradition, fiscal responsibility
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_CONSERVATIVE=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_CONSERVATIVE=gemini

# ----------------------------------------------------
# The Independent - Middle ground, compromise
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_COUNCILOR_INDEPENDENT=gemini-2.5-flash
AUTHOR_TYPE_COUNCILOR_INDEPENDENT=gemini

# ----------------------------------------------------
# Specialist Coder - Technical implementation
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_SPECIALIST_CODE=gemini-2.5-flash
AUTHOR_TYPE_SPECIALIST_CODE=gemini

# ----------------------------------------------------
# Specialist Science - Scientific analysis
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_SPECIALIST_SCIENCE=gemini-2.5-flash
AUTHOR_TYPE_SPECIALIST_SCIENCE=gemini

# ----------------------------------------------------
# Specialist Finance - Financial analysis
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_SPECIALIST_FINANCE=gemini-2.5-flash
AUTHOR_TYPE_SPECIALIST_FINANCE=gemini

# ----------------------------------------------------
# Specialist Medicine - Medical expertise
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_SPECIALIST_MEDICINE=gemini-2.5-flash
AUTHOR_TYPE_SPECIALIST_MEDICINE=gemini

# ----------------------------------------------------
# Specialist Legal - Legal expertise
# Default: gemini-2.5-flash
# ----------------------------------------------------
MODEL_SPECIALIST_LEGAL=gemini-2.5-flash
AUTHOR_TYPE_SPECIALIST_LEGAL=gemini

# =====================================================
# SECTION 3: SERVER SETTINGS
# =====================================================

# Maximum concurrent API requests (1-10, default: 2)
# Higher = faster but more expensive
MAX_CONCURRENT_REQUESTS=2

# Enable economy mode (true/false, default: true)
# Reduces API calls by ~50%, slower but cheaper
ECONOMY_MODE=true

# Enable context pruning (true/false, default: true)
# Removes old messages to save tokens
CONTEXT_PRUNING=true

# Maximum context turns to keep (default: 8)
# Each turn = back-and-forth between councilors
MAX_CONTEXT_TURNS=8

# Custom system directive (optional)
# Additional instructions for all councilors
# CUSTOM_DIRECTIVE=

# =====================================================
# SECTION 4: STORAGE & SESSIONS
# =====================================================

# Session storage directory (default: ./data/sessions)
# SESSION_STORAGE_DIR=./data/sessions

# Auto-save interval in seconds (default: 2)
# How often to save sessions to disk
SESSION_AUTO_SAVE_INTERVAL=2

# Maximum session age in hours (default: 168 = 7 days)
# Old sessions are automatically cleaned up
SESSION_MAX_AGE_HOURS=168

# =====================================================
# SECTION 5: HTTP BRIDGE (Optional)
# =====================================================
# Enable HTTP bridge for non-MCP clients
# Access at http://localhost:4000

# HTTP server port (default: 4000)
# HTTP_PORT=4000

# Enable HTTP bridge (true/false, default: false)
# HTTP_ENABLED=false

# =====================================================
# SECTION 6: LOGGING & DEBUGGING
# =====================================================

# Log level (error, warn, info, debug, default: info)
# LOG_LEVEL=info

# Enable request/response logging (true/false, default: false)
# LOG_REQUESTS=false

# Enable detailed error messages (true/false, default: true)
# DETAILED_ERRORS=true

# =====================================================
# SECTION 7: COST MANAGEMENT
# =====================================================

# Budget limit in USD per session (optional)
# Prevents expensive operations if limit exceeded
# BUDGET_LIMIT_PER_SESSION=

# Budget limit in USD per day (optional)
# BUDGET_LIMIT_PER_DAY=

# Enable cost tracking (true/false, default: true)
# TRACK_COSTS=true

# =====================================================
# SECTION 8: RATE LIMITING
# =====================================================

# Rate limit: max requests per minute (optional)
# RATE_LIMIT_PER_MINUTE=

# Rate limit: max tokens per minute (optional)
# TOKEN_RATE_LIMIT_PER_MINUTE=

# =====================================================
# EXAMPLE CONFIGURATIONS
# =====================================================

# Example 1: Budget-Friendly (Free Local Models)
# -----------------------------------------------
# Use this if you want zero API costs
# 1. Install Ollama: https://ollama.ai
# 2. Pull models: ollama pull llama3:latest
# 3. Uncomment the lines below:
# MODEL_SPEAKER_HIGH_COUNCIL=llama3:latest
# AUTHOR_TYPE_SPEAKER_HIGH_COUNCIL=ollama
# LM_STUDIO_ENDPOINT=
# OLLAMA_ENDPOINT=http://localhost:11434/v1/chat/completions
# ECONOMY_MODE=true
# MAX_CONCURRENT_REQUESTS=1

# Example 2: Optimized Mix (Recommended for testing)
# ----------------------------------------------------
# 1. Use premium model for Speaker (most important)
# 2. Use faster/cheaper models for others
# MODEL_SPEAKER_HIGH_COUNCIL=anthropic/claude-3.5-sonnet
# AUTHOR_TYPE_SPEAKER_HIGH_COUNCIL=openrouter
# MODEL_COUNCILOR_TECHNOCRAT=openai/gpt-4o-mini
# AUTHOR_TYPE_COUNCILOR_TECHNOCRAT=openrouter
# MODEL_COUNCILOR_ETHICIST=gemini-2.5-flash
# AUTHOR_TYPE_COUNCILOR_ETHICIST=gemini
# ECONOMY_MODE=true

# Example 3: High Quality (All Premium Models)
# ---------------------------------------------
# MODEL_SPEAKER_HIGH_COUNCIL=anthropic/claude-3.5-sonnet
# AUTHOR_TYPE_SPEAKER_HIGH_COUNCIL=openrouter
# MODEL_MODERATOR_FACILITATOR=anthropic/claude-3.5-sonnet
# MODEL_COUNCILOR_TECHNOCRAT=anthropic/claude-3.5-sonnet
# MODEL_COUNCILOR_ETHICIST=anthropic/claude-3.5-sonnet
# MODEL_COUNCILOR_PRAGMATIST=openai/gpt-4o
# AUTHOR_TYPE_COUNCILOR_PRAGMATIST=openrouter
# ECONOMY_MODE=false

# =====================================================
# QUICK START GUIDE
# =====================================================

# Step 1: Choose ONE provider and get API key
# - Gemini: https://aistudio.google.com/app/apikey (Easiest)
# - OpenRouter: https://openrouter.ai/keys (Most models)
# - LM Studio: https://lmstudio.ai (Free, local)
# - Ollama: https://ollama.ai (Free, local)

# Step 2: Copy this file to .env
# cp .env.example .env

# Step 3: Add your API key
# GEMINI_API_KEY=your_key_here

# Step 4: (Optional) Configure custom models
# MODEL_SPEAKER_HIGH_COUNCIL=your_preferred_model

# Step 5: Start the server
# ./start.sh      # Linux/Mac
# start.bat       # Windows

# =====================================================
# TROUBLESHOOTING
# =====================================================

# Q: "No AI providers configured" error?
# A: Make sure at least one API key is set (GEMINI_API_KEY, etc.)

# Q: "sessionStorage is not defined" warning?
# A: This is a warning only - sessions still work. Install to fix.

# Q: Session interrupted/cancelled?
# A: This usually means user cancelled or server restarted

# Q: How to reduce costs?
# A: Set ECONOMY_MODE=true, use LM Studio/Ollama (free), or use cheaper models

# Q: How to speed up sessions?
# A: Increase MAX_CONCURRENT_REQUESTS to 4-6

# =====================================================
# MORE HELP
# =====================================================

# Documentation: See README.md
# Interactive Setup: Run start.bat and choose option 2
# Model Configuration: Run start.bat and choose option 3
# Diagnostics: Use council_diagnostics MCP tool
# GitHub: https://github.com/Franzferdinan51/AI-Bot-Council-Concensus

# =====================================================
