{
  "mcpServers": {
    "ai-council": {
      "command": "npm",
      "args": ["run", "mcp", "--"],
      "env": {
        "GEMINI_API_KEY": "your_key_here",
        "OPENROUTER_API_KEY": "",
        "GENERIC_OPENAI_API_KEY": "",
        "GENERIC_OPENAI_ENDPOINT": "",
        "LM_STUDIO_ENDPOINT": "http://localhost:1234/v1/chat/completions",
        "OLLAMA_ENDPOINT": "http://localhost:11434/v1/chat/completions",
        "MAX_CONCURRENT_REQUESTS": "2",
        "ECONOMY_MODE": "true"
      }
    }
  }
}
